# üöÄ Plan d'Impl√©mentation QG - Squad Lamoms V3

**Date** : 2 janvier 2026  
**Objectif** : D√©velopper le QG (Quartier G√©n√©ral) de la Squad Lamoms  
**Co√ªt Phase 1-2** : ~$2/mois  
**Dur√©e** : 2-4 mois (formation)

---

## üéØ Vision Globale

**Cr√©er un QG autonome avec 7 agents IA** pour :
- üõ°Ô∏è Corriger bugs automatiquement (D√©fensif)
- üé® D√©velopper nouvelles fonctionnalit√©s (Cr√©atif)
- üí∞ Conseiller financi√®rement (Social)

**Strat√©gie** : Apprendre avec mod√®les locaux gratuits ‚Üí Upgrade si besoin

---

## üèóÔ∏è Architecture QG

![Architecture QG](C:/Users/djabi/.gemini/antigravity/brain/ede6fef1-d756-4899-840c-0bc3a3c7f96f/architecture_qg_overview_1767394516408.png)

### Les 3 Zones

**Zone Front (Mobile/Web)** :
- LAMOMS-COACH (~$1/mois)

**Zone QG (Serveur PC)** :
- LAMOMS-M√âCANICIEN (Ollama - $0)
- LAMOMS-BIBLIOTH√âCAIRE (ChromaDB - $0)
- LAMOMS-ANALYSTE (Llama 3 - $0)
- LAMOMS-MENTORE (Gemini - ~$1/mois, temporaire)
- LAMOMS-PLANIFICATEUR (Python - $0)

**Zone Cloud (APIs)** :
- LAMOMS-EXPERT (n8n - $0)

---

## üîÑ Les 3 Workflows

### 1. Workflow D√©fensif (Bugs)

![Workflow D√©fensif](C:/Users/djabi/.gemini/antigravity/brain/ede6fef1-d756-4899-840c-0bc3a3c7f96f/workflow_defensif_diagram_1767394460398.png)

**Flux** :
1. COACH d√©tecte bug üêõ
2. BIBLIOTH√âCAIRE cherche dans base üìö
3. **Pr√©-filtre Top 3 solutions** (RAG scoring)
4. Si nouveau ‚Üí EXPERT cherche üåê
5. M√âCANICIEN choisit et fixe üîß
6. COACH notifi√© ‚úÖ

**Innovation** : Pr√©-filtrage intelligent par BIBLIOTH√âCAIRE

---

### 2. Workflow Cr√©atif (Features)

![Workflow Cr√©atif](C:/Users/djabi/.gemini/antigravity/brain/ede6fef1-d756-4899-840c-0bc3a3c7f96f/workflow_creatif_diagram_1767394478688.png)

**Flux** :
1. USER demande feature ‚ú®
2. PLANIFICATEUR organise üìÖ
3. M√âCANICIEN demande docs
4. BIBLIOTH√âCAIRE fournit templates üìö
5. Si manque ‚Üí EXPERT cherche üåê
6. M√âCANICIEN d√©veloppe üîß
7. COACH notifie ‚úÖ

**Innovation** : BIBLIOTH√âCAIRE guide, M√âCANICIEN code

---

### 3. Workflow Social (Conseils)

![Workflow Social](C:/Users/djabi/.gemini/antigravity/brain/ede6fef1-d756-4899-840c-0bc3a3c7f96f/workflow_social_diagram_1767394500472.png)

**Flux** :
1. USER demande conseil üí∞
2. COACH collecte donn√©es
3. ANALYSTE g√©n√®re (ou MENTORE si Phase 1-3) üéì
4. COACH affiche + feedback üëçüëé
5. Si üëç ‚Üí BIBLIOTH√âCAIRE stocke Dataset d'Or üìö

**Innovation** : Apprentissage progressif (teacher-student)

---

## üìÖ Phase 1 : MVP Coach Financier (2 mois)

### Objectif
Cr√©er syst√®me minimal de conseils financiers avec apprentissage

### Architecture Phase 1

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     ZONE FRONT (Streamlit)          ‚îÇ
‚îÇ  LAMOMS-COACH                       ‚îÇ
‚îÇ  - Affiche conseils                 ‚îÇ
‚îÇ  - Collecte feedback üëçüëé           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üï (API REST)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     ZONE QG (Python + LangChain)    ‚îÇ
‚îÇ  LAMOMS-BIBLIOTH√âCAIRE (ChromaDB)   ‚îÇ
‚îÇ  - Stocke logs utilisateur          ‚îÇ
‚îÇ  - Stocke Dataset d'Or              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üï (API)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     ZONE CLOUD                      ‚îÇ
‚îÇ  LAMOMS-MENTORE (Gemini Flash)      ‚îÇ
‚îÇ  - G√©n√®re conseils                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### √âtape 1.1 : Setup Environnement (3-5 jours)

**T√¢ches** :
- [ ] Installer Ollama sur PC
- [ ] T√©l√©charger Llama 3 8B (`ollama pull llama3`)
- [ ] Cr√©er projet Python `squad_lamoms/`
- [ ] Installer d√©pendances :
  ```bash
  pip install langchain langchain-google-genai langchain-community
  pip install chromadb ollama fastapi uvicorn python-dotenv
  ```
- [ ] Configurer API Keys (Gemini)
- [ ] Tester Ollama local

**Structure Projet** :
```
squad_lamoms/
‚îú‚îÄ‚îÄ .env                    # API keys
‚îú‚îÄ‚îÄ requirements.txt        # D√©pendances
‚îú‚îÄ‚îÄ main.py                 # Point d'entr√©e
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ settings.py         # Configuration
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ coach.py            # Agent Coach
‚îÇ   ‚îú‚îÄ‚îÄ mentore.py          # Agent Mentore
‚îÇ   ‚îú‚îÄ‚îÄ mecanicien.py       # Agent M√©canicien (Ollama)
‚îÇ   ‚îî‚îÄ‚îÄ bibliothecaire.py   # Agent Biblioth√©caire
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ vision_scanner.py   # Vision IA (optionnel)
‚îÇ   ‚îî‚îÄ‚îÄ database.py         # Outils DB
‚îú‚îÄ‚îÄ memory/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ chroma_store.py     # ChromaDB wrapper
‚îÇ   ‚îî‚îÄ‚îÄ dataset.py          # Dataset d'Or
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ routes.py           # API REST
‚îî‚îÄ‚îÄ tests/
    ‚îî‚îÄ‚îÄ test_agents.py      # Tests
```

**Livrables** :
- ‚úÖ Environnement Python fonctionnel
- ‚úÖ Ollama + Llama 3 op√©rationnel
- ‚úÖ ChromaDB test√©
- ‚úÖ API Gemini test√©e

---

### √âtape 1.2 : Cr√©er Agent MENTORE (5-7 jours)

**Code Exemple** :
```python
# agents/mentore.py
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import ChatPromptTemplate

MENTORE_PROMPT = """
Tu es LAMOMS-MENTORE, coach financier expert.

Analyse ces donn√©es utilisateur et donne UN conseil actionnable :
{user_data}

Conseil (max 2 phrases, concret et utile) :
"""

class MentoreAgent:
    def __init__(self, api_key: str):
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-1.5-flash",
            api_key=api_key
        )
        self.prompt = ChatPromptTemplate.from_template(MENTORE_PROMPT)
    
    def generate_advice(self, user_data: dict) -> str:
        """G√©n√®re conseil financier."""
        chain = self.prompt | self.llm
        response = chain.invoke({"user_data": user_data})
        return response.content
```

**T√¢ches** :
- [ ] Cr√©er classe `MentoreAgent`
- [ ] Optimiser prompt syst√®me
- [ ] Tester avec vraies donn√©es Gestio V4
- [ ] G√©n√©rer 10 conseils et valider

**Livrables** :
- ‚úÖ Agent MENTORE fonctionnel
- ‚úÖ 10 conseils valid√©s
- ‚úÖ Temps r√©ponse < 5s

---

### √âtape 1.3 : Cr√©er Agent BIBLIOTH√âCAIRE (5-7 jours)

**Code Exemple** :
```python
# memory/chroma_store.py
from langchain_community.vectorstores import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings

class BibliothecaireMemory:
    def __init__(self, api_key: str):
        self.embeddings = GoogleGenerativeAIEmbeddings(
            model="models/embedding-001",
            google_api_key=api_key
        )
        self.vectorstore = Chroma(
            collection_name="dataset_or",
            embedding_function=self.embeddings,
            persist_directory="./chroma_db"
        )
    
    def store_advice(self, advice: str, feedback: str, metadata: dict):
        """Stocke conseil valid√© (üëç)."""
        if feedback == "up":
            self.vectorstore.add_texts(
                texts=[advice],
                metadatas=[metadata]
            )
    
    def search_similar(self, query: str, k: int = 3) -> list:
        """Cherche Top 3 solutions similaires."""
        docs = self.vectorstore.similarity_search(query, k=k)
        return docs
```

**T√¢ches** :
- [ ] Setup ChromaDB
- [ ] Cr√©er syst√®me de stockage
- [ ] Impl√©menter recherche s√©mantique
- [ ] Tester pr√©-filtrage Top 3

**Livrables** :
- ‚úÖ ChromaDB op√©rationnel
- ‚úÖ Stockage conseils valid√©s
- ‚úÖ Recherche Top 3 fonctionnelle

---

### √âtape 1.4 : Cr√©er Agent COACH (3-5 jours)

**Code Exemple** :
```python
# Interface Streamlit
import streamlit as st
import requests

st.title("üí∞ Gestio V4 - Coach Financier")

# Afficher dernier conseil
if st.button("üéØ Demander conseil"):
    conseil = requests.get("http://localhost:8000/api/conseil").json()
    
    st.info(conseil["texte"])
    
    # Feedback
    col1, col2 = st.columns(2)
    with col1:
        if st.button("üëç Utile"):
            requests.post(f"/api/feedback/{conseil['id']}", 
                         json={"vote": "up"})
            st.success("Merci ! Conseil sauvegard√©.")
    
    with col2:
        if st.button("üëé Inutile"):
            requests.post(f"/api/feedback/{conseil['id']}", 
                         json={"vote": "down"})
            st.warning("Merci ! On fera mieux.")
```

**T√¢ches** :
- [ ] Cr√©er interface Streamlit
- [ ] Connecter √† API QG
- [ ] Tester workflow bout-en-bout

**Livrables** :
- ‚úÖ Interface COACH fonctionnelle
- ‚úÖ Workflow complet test√©
- ‚úÖ Premier conseil valid√© üëç

---

## üìÖ Phase 2 : Maintenance Auto (2 mois)

### Objectif
Ajouter M√âCANICIEN + EXPERT pour auto-r√©paration code

### √âtape 2.1 : Cr√©er Agent M√âCANICIEN (7-10 jours)

**Code Exemple** :
```python
# agents/mecanicien.py
from langchain_community.llms import Ollama
from langchain.agents import create_tool_calling_agent
from langchain.tools import tool

MECANICIEN_PROMPT = """
Tu es LAMOMS-M√âCANICIEN, expert en d√©veloppement Python.

Tu re√ßois les 3 meilleures solutions pour un bug.
Choisis la plus adapt√©e et g√©n√®re le code de correction.

Solutions propos√©es :
{solutions}

Contexte du bug :
{bug_context}

G√©n√®re le patch de correction :
"""

class MecanicienAgent:
    def __init__(self):
        self.llm = Ollama(model="llama3")  # Local, gratuit !
        
    def fix_bug(self, solutions: list, bug_context: dict) -> str:
        """Choisit solution et g√©n√®re patch."""
        # M√âCANICIEN analyse les 3 solutions
        # Choisit la meilleure
        # G√©n√®re le code
        pass
```

**T√¢ches** :
- [ ] Cr√©er classe `MecanicienAgent`
- [ ] Int√©grer Ollama local
- [ ] Tester sur bugs r√©els
- [ ] Mesurer qualit√© corrections

**Livrables** :
- ‚úÖ M√âCANICIEN op√©rationnel
- ‚úÖ 5+ bugs corrig√©s
- ‚úÖ Taux succ√®s > 70%

---

### √âtape 2.2 : Am√©liorer BIBLIOTH√âCAIRE (Pr√©-filtrage)

**Code Exemple** :
```python
# agents/bibliothecaire.py
class BibliothecaireAgent:
    def __init__(self, memory: BibliothecaireMemory):
        self.memory = memory
    
    def find_solutions(self, bug_description: str) -> list:
        """Trouve et pr√©-filtre Top 3 solutions."""
        # 1. Recherche s√©mantique
        all_solutions = self.memory.search_similar(bug_description, k=10)
        
        # 2. Scoring avec RAG
        scored = self._score_solutions(all_solutions, bug_description)
        
        # 3. Pr√©-filtrage Top 3
        top_3 = sorted(scored, key=lambda x: x['score'], reverse=True)[:3]
        
        return top_3
    
    def _score_solutions(self, solutions: list, context: str) -> list:
        """Score solutions par pertinence."""
        # Utilise embeddings pour scorer
        pass
```

**T√¢ches** :
- [ ] Impl√©menter scoring RAG
- [ ] Tester pr√©-filtrage
- [ ] Mesurer pr√©cision Top 3

**Livrables** :
- ‚úÖ Pr√©-filtrage op√©rationnel
- ‚úÖ Top 3 pertinent > 80%

---

## üí∞ Co√ªts et Technologies

### Stack Technologique

| Composant | Technologie | Co√ªt |
|-----------|-------------|------|
| **COACH** | Streamlit + Gemini 2.0 Flash | ~$1/mois |
| **M√âCANICIEN** | Ollama + Llama 3 8B | $0 |
| **BIBLIOTH√âCAIRE** | ChromaDB + Embeddings | $0 |
| **ANALYSTE** | Llama 3 8B (local) | $0 |
| **MENTORE** | Gemini 1.5 Flash | ~$1/mois |
| **EXPERT** | n8n + Python requests | $0 |
| **PLANIFICATEUR** | Python + Telegram API | $0 |

**Total Phase 1-2** : **~$2/mois** üéâ

### √âvolution Co√ªts

**Phase 1-2 (Formation)** : ~$2/mois
- Objectif : Apprendre
- Mod√®les locaux gratuits
- Qualit√© suffisante pour formation

**Phase 3+ (Performance)** :
- Si M√âCANICIEN local insuffisant ‚Üí Upgrade Claude (~$10/mois)
- Sinon ‚Üí Rester local ($0)
- D√©cision bas√©e sur r√©sultats

---

## üìä M√©triques de Succ√®s

### Phase 1 (MVP Coach)
- [ ] 20+ conseils g√©n√©r√©s
- [ ] 70%+ satisfaction (üëç)
- [ ] Temps r√©ponse < 5s
- [ ] Co√ªt < $2/mois

### Phase 2 (Maintenance)
- [ ] 5+ bugs auto-corrig√©s
- [ ] 70%+ taux succ√®s corrections
- [ ] 0 r√©gression introduite
- [ ] Co√ªt < $3/mois

---

## üéØ Prochaines √âtapes Imm√©diates

**Vous √™tes ici** : Phase 0 (Apprentissage)

**Avant Phase 1** :
1. ‚úÖ Terminer roadmap apprentissage (LangChain, ChromaDB)
2. ‚è≥ Installer Ollama + Llama 3
3. ‚è≥ Setup environnement Python

**Pendant Phase 1** (Ordre) :
1. **Semaine 1** : Setup + MENTORE
2. **Semaine 2** : BIBLIOTH√âCAIRE + ChromaDB
3. **Semaine 3** : COACH (Streamlit)
4. **Semaine 4** : Tests + Optimisation
5. **Semaines 5-8** : Collecte 20+ feedbacks

---

## üöÄ Vision Long Terme

**Mois 1-2** : MVP Coach fonctionnel (vous comme testeur)  
**Mois 3-4** : Maintenance auto op√©rationnelle  
**Mois 5-12** : Apprentissage ANALYSTE  
**Mois 12+** : Autonomie totale + $0/mois

**Objectif ultime** : QG autonome, intelligent et **gratuit** ! üí™

---

**Pr√™t √† commencer ?** Suivez la roadmap d'apprentissage puis revenez ici pour Phase 1 ! üòä
