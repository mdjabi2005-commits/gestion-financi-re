# -*- coding: utf-8 -*-
"""
Created on Mon Nov 17 20:35:01 2025

@author: djabi
"""

# ==============================
# ğŸ“Š INTERFACE PRINCIPALE
# ==============================

def interface_ocr_analysis_complete():

    st.title("ğŸ” Analyse OCR ComplÃ¨te - Tour de ContrÃ´le")
    st.markdown("Analysez vos propres scans ou diagnostiquez les logs de vos utilisateurs")
    
    # Choix du mode
    tab1,tab2,tab3,tab4 = st.tabs([
        "ğŸ“Š Mes propres scans", "ğŸ”¬ Analyser logs externes", "ğŸ“ˆ Comparaison", "ğŸ› ï¸ Diagnostic complet"
    ])
    
    with tab1:
        # Interface existante pour vos propres logs
        interface_own_scans()
    
    with tab2:
        # Nouvelle interface pour analyser les logs des utilisateurs
        interface_external_logs()
    
    with tab3:
        # Comparaison entre diffÃ©rents logs
        interface_comparison()
    
    with tab4:
        # Diagnostic approfondi avec recommandations
        interface_diagnostic()

def interface_own_scans():
    """Analyse de vos propres scans (interface originale amÃ©liorÃ©e)."""
    
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“ˆ Performance",
        "âœ… Patterns fiables", 
        "âš ï¸ Patterns Ã  corriger",
        "ğŸ“‹ Historique",
        "ğŸ“Š Statistiques dÃ©taillÃ©es"
    ])
    
    with tab1:
        st.subheader("ğŸ“Š Performance Globale")

        # Charger les stats depuis vos fichiers locaux
        perf = get_ocr_performance_report()

        # DEBUG: Afficher ce qui a Ã©tÃ© chargÃ©
        print(f"[DEBUG-ANALYSE] Fichier existe: {os.path.exists(OCR_PERFORMANCE_LOG)}")
        print(f"[DEBUG-ANALYSE] Contenu perf: {perf}")
        print(f"[DEBUG-ANALYSE] Type perf: {type(perf)}")
        print(f"[DEBUG-ANALYSE] ClÃ©s: {list(perf.keys()) if perf else 'None'}")

        # VÃ©rifier si des donnÃ©es existent
        if not perf or (not perf.get('ticket') and not perf.get('revenu')):
            st.info("ğŸ“Š **Aucune donnÃ©e OCR disponible pour le moment**")
            st.markdown("""
            ### ğŸ’¡ Comment gÃ©nÃ©rer des statistiques ?
            
            Les statistiques OCR sont gÃ©nÃ©rÃ©es automatiquement lorsque vous :
            - ğŸ§¾ Scannez des tickets via l'interface OCR
            - ğŸ’¼ Ajoutez des revenus avec OCR
            - ğŸ“¸ Utilisez la fonction d'analyse de documents
            
            **Fichiers requis :**
            - `data/ocr_logs/performance_stats.json` - Statistiques de performance
            - `data/ocr_logs/pattern_stats.json` - Statistiques des patterns
            - `data/ocr_logs/scan_history.jsonl` - Historique des scans
            
            **ğŸ“ Localisation actuelle :**
            - Performance: `{}`
            - Patterns: `{}`
            - Historique: `{}`
            
            ğŸš€ **Commencez Ã  scanner des documents pour voir les statistiques !**
            """.format(
                "âœ… Existe" if os.path.exists(OCR_PERFORMANCE_LOG) else "âŒ Inexistant",
                "âœ… Existe" if os.path.exists(PATTERN_STATS_LOG) else "âŒ Inexistant",
                "âœ… Existe" if os.path.exists(OCR_SCAN_LOG) else "âŒ Inexistant"
            ))
        else:
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown("### ğŸ§¾ Tickets")
                if 'ticket' in perf:
                    ticket_stats = perf['ticket']
                    st.metric("Total scannÃ©s", ticket_stats.get('total', 0))
                    st.metric("Taux succÃ¨s", f"{ticket_stats.get('success_rate', 0):.1f}%")
                    st.metric("Corrections", f"{ticket_stats.get('correction_rate', 0):.1f}%")
                else:
                    st.info("ğŸ“­ Aucun ticket scannÃ©")
            
            with col2:
                st.markdown("### ğŸ’¼ Revenus")
                if 'revenu' in perf:
                    revenu_stats = perf['revenu']
                    st.metric("Total scannÃ©s", revenu_stats.get('total', 0))
                    st.metric("Taux succÃ¨s", f"{revenu_stats.get('success_rate', 0):.1f}%")
                    st.metric("Corrections", f"{revenu_stats.get('correction_rate', 0):.1f}%")
                else:
                    st.info("ğŸ“­ Aucun revenu scannÃ©")
            
            with col3:
                st.markdown("### ğŸ“Š Global")
                total_scans = perf.get('ticket', {}).get('total', 0) + perf.get('revenu', {}).get('total', 0)
                
                if total_scans > 0:
                    avg_success = (
                        (perf.get('ticket', {}).get('success', 0) + perf.get('revenu', {}).get('success', 0)) 
                        / total_scans * 100
                    )
                    st.metric("Total documents", total_scans)
                    st.metric("SuccÃ¨s moyen", f"{avg_success:.1f}%")
                    st.metric("DerniÃ¨re MAJ", perf.get('last_updated', 'N/A')[:10])
                else:
                    st.info("ğŸ“­ Aucune donnÃ©e")
    
    with tab2:
        st.subheader("âœ… Patterns les plus fiables")
        
        min_detections = st.slider("ğŸ”¢ DÃ©tections minimum", 1, 20, 5, key="min_detections_slider")
        min_success = st.slider("ğŸ“ˆ Taux succÃ¨s minimum (%)", 50, 100, 70, key="min_success_slider")
        
        best = get_best_patterns(min_detections, min_success)
        
        if best:
            st.success(f"âœ¨ **{len(best)} patterns fiables trouvÃ©s** avec au moins {min_detections} dÃ©tections et {min_success}% de succÃ¨s")
            
            df = pd.DataFrame(best)
            
            # Graphique
            fig = px.bar(
                df.head(20), 
                x='pattern', 
                y='reliability_score',
                color='success_rate',
                title='ğŸ† Top 20 Patterns Fiables',
                labels={'reliability_score': 'Score de fiabilitÃ©', 'pattern': 'Pattern'},
                color_continuous_scale='Greens'
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # Tableau
            st.dataframe(df, use_container_width=True)
        else:
            st.info("ğŸ“Š **Aucun pattern fiable avec ces critÃ¨res**")
            st.markdown("""
            ### ğŸ’¡ Pourquoi aucun pattern n'est affichÃ© ?
            
            **Raisons possibles :**
            - ğŸ“­ Aucun document n'a encore Ã©tÃ© scannÃ©
            - ğŸ” Les critÃ¨res de filtrage sont trop stricts
            - ğŸ“‰ Les patterns dÃ©tectÃ©s n'atteignent pas les seuils minimum
            
            **Solutions :**
            1. ğŸ”§ RÃ©duisez les critÃ¨res de filtrage ci-dessus
            2. ğŸ§¾ Scannez plus de documents pour gÃ©nÃ©rer des statistiques
            3. ğŸ“ VÃ©rifiez que le fichier `data/ocr_logs/pattern_stats.json` existe
            
            **Ã‰tat actuel :**
            - Fichier patterns: `{}`
            
            ğŸš€ **Astuce :** Commencez par scanner quelques tickets pour alimenter les statistiques !
            """.format(
                "âœ… Existe" if os.path.exists(PATTERN_STATS_LOG) else "âŒ Inexistant - CrÃ©ez-le en scannant des documents"
            ))
    
    with tab3:
        st.subheader("âš ï¸ Patterns problÃ©matiques")
        
        worst = get_worst_patterns(3, 50)
        
        if worst:
            df = pd.DataFrame(worst)
            
            # Alerte
            st.warning(f"ğŸš¨ **{len(worst)} patterns nÃ©cessitent une amÃ©lioration**")
            
            # Graphique des Ã©checs
            fig = px.scatter(
                df,
                x='detections',
                y='success_rate',
                size='corrections',
                color='success_rate',
                hover_data=['pattern'],
                title='âš ï¸ Patterns ProblÃ©matiques (taille = corrections)',
                labels={'success_rate': 'Taux de succÃ¨s (%)', 'detections': 'Nombre de dÃ©tections'},
                color_continuous_scale='RdYlGn'
            )
            fig.add_hline(y=50, line_dash="dash", line_color="red", annotation_text="ğŸš¨ Seuil critique")
            st.plotly_chart(fig, use_container_width=True)
            
            # Recommandations
            st.markdown("### ğŸ’¡ Recommandations d'AmÃ©lioration")
            for idx, row in df.iterrows():
                if row['success_rate'] < 30:
                    st.error(f"ğŸ”´ **{row['pattern']}** : Taux d'Ã©chec critique ({row['success_rate']:.1f}%) - {row['detections']} dÃ©tections")
                elif row['success_rate'] < 40:
                    st.warning(f"ğŸŸ  **{row['pattern']}** : NÃ©cessite attention urgente ({row['success_rate']:.1f}%) - {row['detections']} dÃ©tections")
                else:
                    st.info(f"ğŸŸ¡ **{row['pattern']}** : Ã€ amÃ©liorer ({row['success_rate']:.1f}%) - {row['detections']} dÃ©tections")
        else:
            toast_success("**Aucun pattern problÃ©matique dÃ©tectÃ© !**")
            st.markdown("""
            ### ğŸ‰ Excellent travail !
            
            **Statut actuel :**
            - âœ… Tous les patterns dÃ©tectÃ©s fonctionnent correctement
            - âœ… Aucun pattern n'a un taux d'Ã©chec supÃ©rieur Ã  50%
            - âœ… L'OCR fonctionne de maniÃ¨re optimale
            
            **Ou bien :**
            - ğŸ“­ Aucune donnÃ©e disponible (fichiers logs vides)
            - ğŸ” Les patterns n'ont pas encore Ã©tÃ© testÃ©s suffisamment
            
            **Fichier patterns :**
            - Ã‰tat: `{}`
            
            ğŸ’¡ **Conseil :** Continuez Ã  scanner des documents pour maintenir ces bonnes performances !
            """.format(
                "âœ… Existe" if os.path.exists(PATTERN_STATS_LOG) else "âŒ Inexistant - Commencez Ã  scanner pour gÃ©nÃ©rer des stats"
            ))
    
    with tab4:
        st.subheader("ğŸ“‹ Historique des scans")
        
        col1, col2 = st.columns([2, 1])
        with col1:
            doc_type = st.selectbox("ğŸ—‚ï¸ Type de document", ["Tous", "ticket", "revenu"], key="doc_type_select")
        with col2:
            limit = st.number_input("ğŸ“Š Nombre max", 10, 500, 50, step=10, key="limit_input")
        
        scans = get_scan_history(None if doc_type == "Tous" else doc_type, limit)
        
        if scans:
            # Conversion en DataFrame
            df_scans = pd.DataFrame(scans)
            
            toast_success("**{len(df_scans)} scans trouvÃ©s** dans l'historique")
            
            # Graphique temporel
            if 'timestamp' in df_scans.columns:
                df_scans['timestamp'] = pd.to_datetime(df_scans['timestamp'])
                df_scans['success'] = df_scans['result'].apply(lambda x: x.get('success', False))
                
                # Ã‰volution du taux de succÃ¨s dans le temps
                daily_stats = df_scans.set_index('timestamp').resample('D')['success'].agg(['sum', 'count'])
                daily_stats['success_rate'] = daily_stats['sum'] / daily_stats['count'] * 100
                
                fig = px.line(
                    daily_stats.reset_index(),
                    x='timestamp',
                    y='success_rate',
                    title='ğŸ“ˆ Ã‰volution du Taux de SuccÃ¨s OCR',
                    labels={'success_rate': 'Taux de succÃ¨s (%)', 'timestamp': 'Date'},
                    markers=True
                )
                fig.update_traces(line_color='#10b981', line_width=3)
                st.plotly_chart(fig, use_container_width=True)
            
            # Tableau dÃ©taillÃ©
            st.markdown("### ğŸ“Š Derniers Scans")
            st.dataframe(df_scans[['timestamp', 'document_type', 'filename']].head(20), use_container_width=True)
        else:
            st.info("ğŸ“­ **Aucun scan dans l'historique**")
            st.markdown("""
            ### ğŸ’¡ Comment gÃ©nÃ©rer un historique ?
            
            **L'historique des scans se remplit automatiquement lorsque vous :**
            - ğŸ§¾ Scannez des tickets de caisse
            - ğŸ’¼ Ajoutez des revenus avec reconnaissance OCR
            - ğŸ“¸ Utilisez n'importe quelle fonction d'analyse de documents
            
            **Fichier d'historique :**
            - Chemin: `data/ocr_logs/scan_history.jsonl`
            - Ã‰tat: `{}`
            
            **Structure attendue :**
            Chaque scan gÃ©nÃ¨re une entrÃ©e avec :
            - ğŸ“… Timestamp (date et heure)
            - ğŸ“„ Type de document (ticket/revenu)
            - ğŸ“ Nom du fichier
            - âœ… RÃ©sultat (succÃ¨s/Ã©chec)
            
            ğŸš€ **Commencez Ã  scanner pour voir l'historique se remplir !**
            """.format(
                "âœ… Existe" if os.path.exists(OCR_SCAN_LOG) else "âŒ Inexistant - Sera crÃ©Ã© au premier scan"
            ))
    
    with tab5:
        st.subheader("ğŸ“Š Statistiques dÃ©taillÃ©es")
        
        # Analyses avancÃ©es
        scans = get_scan_history(limit=1000)
        
        if scans:
            df = pd.DataFrame(scans)
            
            st.success(f"ğŸ“ˆ **Analyse de {len(df)} scans** (limitÃ© Ã  1000 les plus rÃ©cents)")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # Distribution des montants
                st.markdown("### ğŸ’° Distribution des montants")
                
                montants = []
                for scan in scans:
                    if 'extraction' in scan:
                        montant = scan['extraction'].get('montant_final', 0)
                        if montant > 0:
                            montants.append(montant)
                
                if montants:
                    fig = px.histogram(
                        montants,
                        nbins=30,
                        title="ğŸ’µ Distribution des montants scannÃ©s",
                        labels={'value': 'Montant (â‚¬)', 'count': 'FrÃ©quence'},
                        color_discrete_sequence=['#10b981']
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    # Statistiques
                    st.markdown(f"""
                    **ğŸ“Š Statistiques des montants :**
                    - ğŸ’° Total: {sum(montants):.2f} â‚¬
                    - ğŸ“Š Moyenne: {sum(montants)/len(montants):.2f} â‚¬
                    - ğŸ“ˆ Maximum: {max(montants):.2f} â‚¬
                    - ğŸ“‰ Minimum: {min(montants):.2f} â‚¬
                    """)
                else:
                    st.info("ğŸ’­ Aucun montant valide extrait des scans")
            
            with col2:
                # CatÃ©gories les plus frÃ©quentes
                st.markdown("### ğŸ“‚ CatÃ©gories dÃ©tectÃ©es")
                
                categories = []
                for scan in scans:
                    if 'extraction' in scan:
                        cat = scan['extraction'].get('categorie_final', 'autres')
                        if cat:
                            categories.append(cat)
                
                if categories:
                    cat_counts = pd.Series(categories).value_counts().head(10)
                    
                    fig = px.pie(
                        values=cat_counts.values,
                        names=cat_counts.index,
                        title="ğŸ† Top 10 CatÃ©gories",
                        color_discrete_sequence=px.colors.sequential.Greens_r
                    )
                    st.plotly_chart(fig, use_container_width=True)
                    
                    st.markdown(f"""
                    **ğŸ“‹ RÃ©partition :**
                    - ğŸ”¢ CatÃ©gories uniques: {len(cat_counts)}
                    - ğŸ‘‘ Plus frÃ©quente: {cat_counts.index[0]} ({cat_counts.values[0]} fois)
                    """)
                else:
                    st.info("ğŸ’­ Aucune catÃ©gorie dÃ©tectÃ©e dans les scans")
            
            # Graphique temporel additionnel
            st.markdown("### ğŸ“… ActivitÃ© de Scan")
            if 'timestamp' in df.columns:
                df['timestamp'] = pd.to_datetime(df['timestamp'])
                df['date'] = df['timestamp'].dt.date
                
                daily_counts = df.groupby('date').size().reset_index(name='count')
                
                fig = px.bar(
                    daily_counts,
                    x='date',
                    y='count',
                    title='ğŸ“Š Nombre de scans par jour',
                    labels={'date': 'Date', 'count': 'Nombre de scans'},
                    color='count',
                    color_continuous_scale='Greens'
                )
                st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("ğŸ“­ **Aucune statistique dÃ©taillÃ©e disponible**")
            st.markdown("""
            ### ğŸ’¡ GÃ©nÃ©ration des statistiques dÃ©taillÃ©es
            
            **Cette section affiche :**
            - ğŸ’° Distribution des montants extraits par OCR
            - ğŸ“‚ RÃ©partition par catÃ©gories automatiques
            - ğŸ“… ActivitÃ© de scan journaliÃ¨re
            - ğŸ“ˆ Tendances et patterns d'utilisation
            
            **Pour gÃ©nÃ©rer ces statistiques :**
            1. ğŸ§¾ Scannez des tickets de caisse
            2. ğŸ’¼ Ajoutez des revenus avec OCR
            3. ğŸ“¸ Utilisez l'extraction automatique de donnÃ©es
            
            **Fichier requis :**
            - Chemin: `data/ocr_logs/scan_history.jsonl`
            - Ã‰tat: `{}`
            - Format: JSONL (une ligne JSON par scan)
            
            **DonnÃ©es extraites par scan :**
            - ğŸ“… Timestamp
            - ğŸ’° Montant (montant_final)
            - ğŸ“‚ CatÃ©gorie (categorie_final)
            - âœ… Statut de rÃ©ussite
            
            ğŸš€ **Commencez Ã  scanner pour voir des statistiques riches !**
            """.format(
                "âœ… Existe" if os.path.exists(OCR_SCAN_LOG) else "âŒ Inexistant - CrÃ©Ã© automatiquement au premier scan"
            ))

def interface_external_logs():

    st.subheader("ğŸ”¬ Analyse de Logs Externes")
    st.info("ğŸ’¡ **FonctionnalitÃ© en dÃ©veloppement**")
    st.markdown("""
    ### ğŸ“¤ Upload de Logs Utilisateurs

    Cette section permettra d'analyser les logs OCR de vos utilisateurs pour :
    - ğŸ” Diagnostiquer les problÃ¨mes d'OCR
    - ğŸ“Š Comparer les performances entre utilisateurs
    - ğŸ› Identifier les patterns problÃ©matiques

    **Formats supportÃ©s :**
    - `pattern_log.json` - Statistiques des patterns
    - `scan_history.jsonl` - Historique des scans
    - `performance_stats.json` - MÃ©triques de performance

    ğŸš§ **Statut :** En cours de dÃ©veloppement
    """)

    # Interface basique d'upload
    uploaded_file = st.file_uploader(
        "ğŸ“ Uploader un fichier de logs (JSON/JSONL)",
        type=['json', 'jsonl', 'txt'],
        help="Uploadez les logs d'un utilisateur pour analyse"
    )

    if uploaded_file:
        toast_success("Fichier '{uploaded_file.name}' uploadÃ© avec succÃ¨s !")

        # Analyser le fichier uploadÃ©
        data = analyze_external_log(uploaded_file)

        if data:
            # Diagnostic des donnÃ©es
            diagnostics = diagnose_ocr_patterns(data)

            # MÃ©triques principales
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("Total scans", diagnostics.get('total_scans', 0))

            with col2:
                success_rate = diagnostics.get('success_rate', 0)
                st.metric(
                    "Taux de succÃ¨s",
                    f"{success_rate:.1f}%",
                    delta=f"{success_rate - 70:.1f}%" if success_rate > 0 else None
                )

            with col3:
                st.metric(
                    "Patterns fiables",
                    len(diagnostics.get('reliable_patterns', []))
                )

            with col4:
                st.metric(
                    "Patterns problÃ©matiques",
                    len(diagnostics.get('problematic_patterns', []))
                )

            # Affichage selon le type
            if isinstance(data, dict) and data.get('type') == 'pattern_counts':
                st.markdown("#### ğŸ“Š Compteurs de patterns")

                patterns = data['data']
                df = pd.DataFrame([
                    {'Pattern': k, 'DÃ©tections': v}
                    for k, v in sorted(patterns.items(), key=lambda x: x[1], reverse=True)
                ])

                # Graphique
                fig = px.bar(
                    df.head(20),
                    x='Pattern',
                    y='DÃ©tections',
                    title='Top 20 Patterns DÃ©tectÃ©s'
                )
                st.plotly_chart(fig, use_container_width=True)

                # Tableau complet
                st.dataframe(df, use_container_width=True)

            elif isinstance(data, list):
                st.markdown("#### ğŸ“‹ Analyse dÃ©taillÃ©e des scans")

                # Patterns problÃ©matiques
                if diagnostics.get('problematic_patterns'):
                    toast_error("Patterns problÃ©matiques dÃ©tectÃ©s :")

                    for pattern_info in diagnostics['problematic_patterns']:
                        st.warning(
                            f"âš ï¸ **{pattern_info['pattern']}** : "
                            f"SuccÃ¨s {pattern_info['success_rate']:.1f}% sur {pattern_info['detections']} dÃ©tections"
                        )

                # Patterns fiables
                if diagnostics.get('reliable_patterns'):
                    toast_success("Patterns fiables :")

                    for pattern_info in diagnostics['reliable_patterns']:
                        st.info(
                            f"âœ“ **{pattern_info['pattern']}** : "
                            f"SuccÃ¨s {pattern_info['success_rate']:.1f}% sur {pattern_info['detections']} dÃ©tections"
                        )

            # Recommandations
            if diagnostics.get('recommendations'):
                st.markdown("### ğŸ’¡ Recommandations")
                for rec in diagnostics['recommendations']:
                    st.markdown(f"- {rec}")

            # Export du diagnostic
            if st.button(f"ğŸ’¾ Exporter diagnostic - {uploaded_file.name}"):
                diagnostic_json = json.dumps(diagnostics, indent=2, ensure_ascii=False)
                st.download_button(
                    "ğŸ“¥ TÃ©lÃ©charger le diagnostic",
                    diagnostic_json,
                    f"diagnostic_{uploaded_file.name}",
                    mime="application/json"
                )
        else:
            toast_error("Impossible d'analyser {uploaded_file.name}")

    else:
        st.info("ğŸ‘† Uploadez les fichiers de logs pour commencer l'analyse")

        # Instructions
        with st.expander("ğŸ“– Instructions pour les utilisateurs"):
            st.markdown("""
            ### Comment rÃ©cupÃ©rer vos logs OCR :

            1. **pattern_log.json** : Compteurs de patterns dÃ©tectÃ©s
               - Chemin : `data/ocr_logs/pattern_log.json`

            2. **scan_history.jsonl** : Historique complet des scans
               - Chemin : `data/ocr_logs/scan_history.jsonl`

            3. **performance_stats.json** : Statistiques de performance
               - Chemin : `data/ocr_logs/performance_stats.json`

            4. **pattern_stats.json** : Statistiques dÃ©taillÃ©es par pattern
               - Chemin : `data/ocr_logs/pattern_stats.json`

            ### Format des logs :
            - JSON : Fichiers structurÃ©s avec statistiques
            - JSONL : Une ligne JSON par scan (historique)
            - TXT : Extraction basique de patterns
            """)

def interface_comparison():
    """Comparaison entre diffÃ©rents logs/utilisateurs."""

    st.subheader("ğŸ“ˆ Comparaison Multi-Sources")
    st.info("ğŸ’¡ **FonctionnalitÃ© en dÃ©veloppement**")
    st.markdown("""
    ### ğŸ”€ Analyse Comparative

    Cette section permettra de comparer :
    - ğŸ‘¥ Performances entre diffÃ©rents utilisateurs
    - ğŸ“… Ã‰volution dans le temps
    - ğŸ¢ Comparaison entre succursales/Ã©quipes
    - ğŸŒ Analyse gÃ©ographique

    **MÃ©triques comparÃ©es :**
    - ğŸ“Š Taux de succÃ¨s OCR
    - ğŸ¯ Patterns les plus fiables
    - âš ï¸ Patterns problÃ©matiques
    - ğŸ’° Montants moyens dÃ©tectÃ©s
    - â±ï¸ Temps de traitement

    **Visualisations :**
    - ğŸ“Š Graphiques comparatifs
    - ğŸ“ˆ Tendances temporelles
    - ğŸ¯ Heatmaps de performance

    ğŸš§ **Statut :** En cours de dÃ©veloppement
    """)

    # Interface basique
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("#### ğŸ“ Source 1")
        file1 = st.file_uploader("Logs utilisateur 1", type=['json', 'jsonl'], key="comp1")
    with col2:
        st.markdown("#### ğŸ“ Source 2")
        file2 = st.file_uploader("Logs utilisateur 2", type=['json', 'jsonl'], key="comp2")

    # Si au moins 2 fichiers sont uploadÃ©s
    if file1 and file2:
        toast_success("Analyse comparative de 2 sources")

        # Analyser les deux fichiers
        data1 = analyze_external_log(file1)
        data2 = analyze_external_log(file2)

        if data1 and data2:
            # Diagnostics
            diag1 = diagnose_ocr_patterns(data1)
            diag2 = diagnose_ocr_patterns(data2)

            comparisons = {
                file1.name: diag1,
                file2.name: diag2
            }

            # Tableau comparatif
            comparison_data = []
            for filename, diag in comparisons.items():
                comparison_data.append({
                    'Fichier': filename[:30],
                    'Scans': diag.get('total_scans', 0),
                    'SuccÃ¨s (%)': f"{diag.get('success_rate', 0):.1f}",
                    'Patterns OK': len(diag.get('reliable_patterns', [])),
                    'Patterns KO': len(diag.get('problematic_patterns', []))
                })

            df_comp = pd.DataFrame(comparison_data)
            st.dataframe(df_comp, use_container_width=True)

            # Graphiques comparatifs
            col1, col2 = st.columns(2)

            with col1:
                # Taux de succÃ¨s
                fig = px.bar(
                    df_comp,
                    x='Fichier',
                    y='SuccÃ¨s (%)',
                    title='Comparaison Taux de SuccÃ¨s',
                    color='SuccÃ¨s (%)'
                )
                st.plotly_chart(fig, use_container_width=True)

            with col2:
                # Patterns problÃ©matiques
                fig = px.bar(
                    df_comp,
                    x='Fichier',
                    y=['Patterns OK', 'Patterns KO'],
                    title='Patterns Fiables vs ProblÃ©matiques',
                    barmode='group'
                )
                st.plotly_chart(fig, use_container_width=True)

            # Patterns communs problÃ©matiques
            st.markdown("### ğŸ” Patterns problÃ©matiques communs")

            all_problematic = {}
            for filename, diag in comparisons.items():
                for pattern_info in diag.get('problematic_patterns', []):
                    pattern = pattern_info['pattern']
                    if pattern not in all_problematic:
                        all_problematic[pattern] = []
                    all_problematic[pattern].append(filename)

            # Afficher les patterns prÃ©sents dans plusieurs fichiers
            common_problems = {k: v for k, v in all_problematic.items() if len(v) > 1}

            if common_problems:
                for pattern, files in common_problems.items():
                    toast_warning("**{pattern}** problÃ©matique dans : {', '.join(files)}")
            else:
                toast_success("Aucun pattern problÃ©matique commun")
        else:
            toast_error("Erreur lors de l'analyse des fichiers")
    else:
        st.info("ğŸ‘† Uploadez au moins 2 fichiers pour comparer")

def interface_diagnostic():

    st.subheader("ğŸ› ï¸ Diagnostic Complet OCR")
    st.info("ğŸ’¡ **FonctionnalitÃ© en dÃ©veloppement**")

    st.markdown("""
    ### ğŸ” Analyse Approfondie

    Cette section fournira un diagnostic complet de votre systÃ¨me OCR :

    **Analyses incluses :**
    - ğŸ¯ Taux de succÃ¨s global et par type
    - ğŸ“Š Performance par pattern
    - âš ï¸ Identification des points faibles
    - ğŸ’¡ Recommandations d'amÃ©lioration
    - ğŸ”§ Suggestions de configuration

    **Niveaux de diagnostic :**
    - âš¡ **Rapide** : Vue d'ensemble (1-2 min)
    - ğŸ“Š **Standard** : Analyse dÃ©taillÃ©e (3-5 min)
    - ğŸ”¬ **Approfondie** : Audit complet (5-10 min)

    **Rapports gÃ©nÃ©rÃ©s :**
    - ğŸ“„ RÃ©sumÃ© exÃ©cutif
    - ğŸ“ˆ Graphiques de tendances
    - ğŸ¯ Liste d'actions prioritaires
    - ğŸ“‹ Guide d'optimisation

    ğŸš§ **Statut :** En cours de dÃ©veloppement
    """)

    # Interface basique de sÃ©lection
    col1, col2 = st.columns(2)

    with col1:
        st.markdown("#### ğŸ“Š Source des donnÃ©es")
        source = st.radio(
            "SÃ©lectionner",
            ["ğŸ’¾ Mes logs locaux", "ğŸ“¤ Upload fichier externe"],
            label_visibility="collapsed"
        )

    with col2:
        st.markdown("#### ğŸ” Profondeur d'analyse")
        depth = st.select_slider(
            "Niveau",
            ["âš¡ Rapide", "ğŸ“Š Standard", "ğŸ”¬ Approfondie"],
            label_visibility="collapsed"
        )

    st.info(f"ğŸ”§ Analyse {depth} en cours d'implÃ©mentation...")

    # AperÃ§u de ce qui sera disponible
    with st.expander("ğŸ‘€ AperÃ§u du futur rapport"):
        st.markdown("""
        **Le diagnostic complet inclura :**

        1. **ğŸ“Š Vue d'ensemble**
           - Nombre total de scans
           - Taux de succÃ¨s global
           - Tendances sur 7/30 jours

        2. **ğŸ¯ Analyse par Pattern**
           - Top 10 patterns fiables
           - Top 10 patterns problÃ©matiques
           - Suggestions d'optimisation

        3. **âš ï¸ Points d'attention**
           - Erreurs critiques
           - DÃ©gradations de performance
           - Patterns Ã  surveiller

        4. **ğŸ’¡ Recommandations**
           - Actions prioritaires
           - Ajustements de configuration
           - Formation recommandÃ©e

        5. **ğŸ“ˆ Projections**
           - Ã‰volution attendue
           - Objectifs rÃ©alistes
           - ROI estimÃ©
        """)


